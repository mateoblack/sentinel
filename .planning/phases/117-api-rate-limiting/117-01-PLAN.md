---
phase: 117-api-rate-limiting
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [ratelimit/types.go, ratelimit/types_test.go, ratelimit/memory.go, ratelimit/memory_test.go, lambda/config.go, lambda/handler.go, lambda/handler_test.go]
autonomous: true
---

<objective>
Implement API rate limiting types and Lambda TVM integration.

Purpose: Protect Lambda TVM endpoint from abuse with configurable per-user and per-IP rate limits. Security hardening phase to prevent credential vending abuse.
Output: Reusable rate limiter types with in-memory implementation, Lambda TVM rate limiting via handler middleware.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/116-dynamodb-encryption/116-01-SUMMARY.md

# Existing rate limiting patterns to follow
@breakglass/ratelimit.go

# Lambda handler to extend
@lambda/handler.go
@lambda/config.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create rate limiter types and interfaces</name>
  <files>ratelimit/types.go, ratelimit/types_test.go</files>
  <action>
Create a new `ratelimit` package with generic API rate limiting types:

1. `RateLimiter` interface:
   ```go
   type RateLimiter interface {
       // Allow checks if a request should be allowed for the given key.
       // Returns (allowed, retryAfter, error).
       // retryAfter indicates when to retry if blocked (0 if allowed).
       Allow(ctx context.Context, key string) (bool, time.Duration, error)
   }
   ```

2. `Config` struct for rate limit configuration:
   ```go
   type Config struct {
       // RequestsPerWindow is the max requests allowed in Window.
       RequestsPerWindow int
       // Window is the time window for counting requests.
       Window time.Duration
       // BurstSize allows short bursts above the rate (optional, defaults to RequestsPerWindow).
       BurstSize int
   }
   ```

3. `Result` struct for detailed rate limit results:
   ```go
   type Result struct {
       Allowed     bool
       Remaining   int           // Requests remaining in window
       RetryAfter  time.Duration // When to retry if blocked
       ResetAt     time.Time     // When the window resets
   }
   ```

4. Validation method on Config to ensure values are positive.

Follow patterns from breakglass/ratelimit.go but simplify for API rate limiting (no profile-specific rules, just key-based limits).

Test validation logic - invalid config should return errors.
  </action>
  <verify>go test ./ratelimit/... -v -run TestConfig</verify>
  <done>RateLimiter interface and Config types defined with validation tests passing</done>
</task>

<task type="auto">
  <name>Task 2: Implement in-memory rate limiter with token bucket</name>
  <files>ratelimit/memory.go, ratelimit/memory_test.go</files>
  <action>
Create an in-memory rate limiter using token bucket algorithm:

1. `MemoryRateLimiter` struct:
   - Internal map of key -> bucket state (protected by sync.RWMutex)
   - Background cleanup of expired entries (avoid memory leak)
   - Thread-safe for concurrent Lambda invocations

2. Implementation details:
   - Use sliding window log algorithm (simpler than token bucket for Lambda):
     - Store list of request timestamps per key
     - Count requests in last Window period
     - If count >= RequestsPerWindow, reject
   - Cleanup expired entries every 10 minutes (configurable)
   - For Lambda: each invocation shares memory within warm instance

3. Constructor:
   ```go
   func NewMemoryRateLimiter(cfg Config) (*MemoryRateLimiter, error)
   ```

4. Implement `Allow(ctx, key)` method:
   - Lock the bucket for the key
   - Remove expired timestamps (older than Window)
   - Check count against RequestsPerWindow
   - If allowed, add current timestamp
   - Return (allowed, retryAfter if blocked)

5. Add `Close()` method to stop background cleanup goroutine.

Tests should cover:
- Basic allow/deny behavior
- Window expiration (requests allowed after window)
- Concurrent access safety
- Cleanup of expired entries
  </action>
  <verify>go test ./ratelimit/... -v -race</verify>
  <done>In-memory rate limiter passing tests including race detection</done>
</task>

<task type="auto">
  <name>Task 3: Integrate rate limiting into Lambda TVM handler</name>
  <files>lambda/config.go, lambda/handler.go, lambda/handler_test.go</files>
  <action>
Add rate limiting to Lambda TVM handler:

1. In `config.go`:
   - Add new environment variables:
     ```go
     EnvRateLimitRequests = "SENTINEL_RATE_LIMIT_REQUESTS" // default: 100
     EnvRateLimitWindow   = "SENTINEL_RATE_LIMIT_WINDOW"   // default: 60 (seconds)
     ```
   - Add `RateLimiter ratelimit.RateLimiter` field to TVMConfig
   - In LoadConfigFromEnv, create MemoryRateLimiter if requests > 0:
     - Parse SENTINEL_RATE_LIMIT_REQUESTS (default 100 requests)
     - Parse SENTINEL_RATE_LIMIT_WINDOW (default 60 seconds)
     - If requests == 0, rate limiting disabled (nil limiter)

2. In `handler.go` HandleRequest method:
   - Early check BEFORE policy evaluation (minimize work for rejected requests)
   - Extract rate limit key: use caller's IAM user ARN (from ExtractCallerIdentity)
   - If RateLimiter is configured:
     ```go
     if h.Config.RateLimiter != nil {
         allowed, retryAfter, err := h.Config.RateLimiter.Allow(ctx, caller.UserARN)
         if err != nil {
             log.Printf("WARNING: Rate limit check failed: %v", err)
             // Fail open - allow the request if rate limiter errors
         } else if !allowed {
             log.Printf("RATE_LIMITED: user=%s retry_after=%v", username, retryAfter)
             return errorResponse(http.StatusTooManyRequests, "RATE_LIMITED",
                 fmt.Sprintf("Rate limit exceeded. Retry after %v", retryAfter))
         }
     }
     ```
   - Fail-open on rate limiter errors (availability over strict limiting)

3. In `handler_test.go`:
   - Add test for rate limiting behavior
   - Test that requests are rejected after limit exceeded
   - Test that rate limiter errors result in fail-open
   - Test that disabled rate limiter (nil) works normally

Security note: Rate limit by user ARN, not IP. IAM auth already identifies the caller, and IP-based limiting could block legitimate users behind NAT.
  </action>
  <verify>go test ./lambda/... -v -run TestHandler</verify>
  <done>Lambda handler rate limiting working with tests passing, 429 returned when limit exceeded</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `go build ./...` succeeds without errors
- [ ] `go test ./ratelimit/... -v -race` passes
- [ ] `go test ./lambda/... -v` passes
- [ ] Rate limiting types are reusable for credential server (Plan 02)
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No errors or warnings introduced
- Lambda TVM returns 429 when rate limit exceeded
- Rate limiter fails open on errors (availability)
- Types reusable for credential server integration
</success_criteria>

<output>
After completion, create `.planning/phases/117-api-rate-limiting/117-01-SUMMARY.md`
</output>
