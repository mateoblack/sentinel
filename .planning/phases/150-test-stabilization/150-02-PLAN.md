---
phase: 150-test-stabilization
plan: 02
type: execute
wave: 1
depends_on: []
files_modified: [server/coverage_test.go, request/coverage_test.go]
autonomous: true
---

<objective>
Fix test failures and achieve coverage targets in server and request packages.

Purpose: The server and request packages handle credential serving and approval workflows. Both are security-sensitive and mentioned specifically in the phase requirements as having test failures.
Output: All tests passing in server and request packages, coverage at acceptable levels.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@server/peercred.go
@server/peercred_test.go
@server/process_auth.go
@server/process_auth_test.go
@server/security_test.go
@request/dynamodb.go
@request/dynamodb_test.go
@request/security_regression_test.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run and fix server package tests</name>
  <files>server/peercred_test.go, server/process_auth_test.go, server/unix_server_test.go</files>
  <action>
  1. Run tests: `go test -v ./server/...`
  2. If any tests fail, analyze the failure:
     - If test is platform-specific (Unix sockets, peercred), add appropriate build tags or skip on unsupported platforms
     - If test has race conditions, add proper synchronization
     - If test has stale expectations, update to match current behavior
  3. For platform-specific code (peercred_linux.go, peercred_darwin.go):
     - Ensure tests gracefully skip on unsupported platforms using runtime.GOOS checks
     - Add `// +build linux darwin` tags if needed
  4. Verify all server tests pass: `go test -v ./server/...`

  Server package is critical for credential serving security.
  </action>
  <verify>go test -v ./server/... shows PASS for all tests</verify>
  <done>All server package tests pass</done>
</task>

<task type="auto">
  <name>Task 2: Run and fix request package tests</name>
  <files>request/dynamodb_test.go, request/state_security_test.go</files>
  <action>
  1. Run tests: `go test -v ./request/...`
  2. If any tests fail, analyze the failure:
     - DynamoDB mocks may need updates for new API patterns
     - State machine tests may have timing issues
     - Security tests may have outdated threat scenarios
  3. Fix any failing tests by:
     - Updating mock expectations to match current implementation
     - Adding proper test isolation (separate DynamoDB table names)
     - Fixing any assertion mismatches
  4. Verify all request tests pass: `go test -v ./request/...`

  Request package handles approval workflow state machine.
  </action>
  <verify>go test -v ./request/... shows PASS for all tests</verify>
  <done>All request package tests pass</done>
</task>

<task type="auto">
  <name>Task 3: Achieve security package coverage (80%)</name>
  <files>security/v118_integration_test.go</files>
  <action>
  1. Run `go test -cover ./security/...` to measure current coverage
  2. The security package contains v1.18 integration tests
  3. If coverage is below 80%, identify uncovered code paths
  4. Add tests for any uncovered security validation logic
  5. Re-measure to confirm 80% target

  Note: The "security" package may be a test-only package for integration tests.
  If it only contains test files, coverage is N/A - document this finding.
  </action>
  <verify>go test -cover ./security/... shows coverage >= 80% OR document that package is test-only</verify>
  <done>Security package coverage target met or documented as test-only</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] go test ./server/... PASS
- [ ] go test ./request/... PASS
- [ ] go test ./security/... PASS (or documented as test-only)
- [ ] No flaky tests introduced
</verification>

<success_criteria>

- All server package tests pass
- All request package tests pass
- Security package coverage at 80% or documented exception
- No test regressions
</success_criteria>

<output>
After completion, create `.planning/phases/150-test-stabilization/150-02-SUMMARY.md`
</output>
