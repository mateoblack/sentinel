---
phase: 57-performance-load-testing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [policy/benchmark_test.go, identity/benchmark_test.go, breakglass/benchmark_test.go]
autonomous: true
---

<objective>
Create Go benchmarks for performance-critical hot paths in policy evaluation, identity generation, and rate limiting.

Purpose: Establish baseline performance metrics and identify optimization opportunities in the credential issuance path.
Output: Benchmark tests with ns/op, allocs/op metrics for core operations.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@policy/evaluate.go
@policy/cache.go
@identity/request_id.go
@breakglass/ratelimit.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create policy evaluation benchmarks</name>
  <files>policy/benchmark_test.go</files>
  <action>
Create benchmark tests for policy evaluation hot paths:

1. BenchmarkEvaluate_SimpleRule - single rule, direct match
2. BenchmarkEvaluate_MultipleRules - 10 rules, match on last rule (worst case)
3. BenchmarkEvaluate_TimeWindow - rule with time window constraint
4. BenchmarkEvaluate_NoMatch - default deny path (no matching rule)
5. BenchmarkCachedLoader_Hit - cache hit path (no underlying load)
6. BenchmarkCachedLoader_Miss - cache miss path (fresh load)

Use table-driven benchmark setup with b.Run() for sub-benchmarks.
Reset timer after setup: b.ResetTimer()
Report allocations: b.ReportAllocs()

Create realistic policy fixtures:
- smallPolicy: 1 rule with user/profile match
- mediumPolicy: 10 rules with conditions
- largePolicy: 50 rules (stress test)

Use time.Date() for deterministic time in benchmarks, not time.Now().
  </action>
  <verify>go test -bench=. -benchmem ./policy/... runs all benchmarks without errors</verify>
  <done>Policy benchmarks report ns/op and allocs/op for all evaluation paths</done>
</task>

<task type="auto">
  <name>Task 2: Create identity generation benchmarks</name>
  <files>identity/benchmark_test.go</files>
  <action>
Create benchmark tests for identity operations:

1. BenchmarkNewRequestID - request ID generation (crypto/rand)
2. BenchmarkValidateRequestID - regex validation
3. BenchmarkBuildSourceIdentity - SourceIdentity string building
4. BenchmarkParseSourceIdentity - SourceIdentity parsing
5. BenchmarkSanitizeUser - user string sanitization

Focus on allocation tracking since these are called per-request.
Use b.ReportAllocs() on all benchmarks.

For BenchmarkNewRequestID, note that crypto/rand performance varies by OS.
Document expected allocation counts in comments.
  </action>
  <verify>go test -bench=. -benchmem ./identity/... runs all benchmarks without errors</verify>
  <done>Identity benchmarks report ns/op and allocs/op for all operations</done>
</task>

<task type="auto">
  <name>Task 3: Create rate limiting benchmarks</name>
  <files>breakglass/benchmark_test.go</files>
  <action>
Create benchmark tests for rate limiting hot paths:

1. BenchmarkFindRateLimitRule_FirstMatch - immediate match
2. BenchmarkFindRateLimitRule_LastMatch - worst case (10 rules, match on last)
3. BenchmarkFindRateLimitRule_NoMatch - no matching rule
4. BenchmarkContainsOrEmpty_Empty - empty slice (wildcard)
5. BenchmarkContainsOrEmpty_Found - value found in slice
6. BenchmarkContainsOrEmpty_NotFound - value not in slice

Create rate limit policy fixtures:
- singleRulePolicy: 1 rule
- multiRulePolicy: 10 rules with different profiles

Use b.ReportAllocs() on all benchmarks.
These paths are hit on every break-glass invocation.
  </action>
  <verify>go test -bench=. -benchmem ./breakglass/... runs all benchmarks without errors</verify>
  <done>Rate limiting benchmarks report ns/op and allocs/op for rule matching</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] go test -bench=. -benchmem ./policy/... succeeds
- [ ] go test -bench=. -benchmem ./identity/... succeeds
- [ ] go test -bench=. -benchmem ./breakglass/... succeeds
- [ ] All benchmarks report ns/op and allocs/op
- [ ] No test failures introduced
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Benchmark files follow Go conventions (*_test.go with Benchmark* functions)
- Baseline metrics established for critical paths
  </success_criteria>

<output>
After completion, create `.planning/phases/57-performance-load-testing/57-01-SUMMARY.md`
</output>
